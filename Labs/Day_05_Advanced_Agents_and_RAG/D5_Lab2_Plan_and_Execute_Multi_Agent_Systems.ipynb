{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 5 - Lab 2: Plan-and-Execute & Multi-Agent Systems\n",
    "\n",
    "**Objective:** Explore advanced agent architectures, including the plan-and-execute model and conversational multi-agent systems using Microsoft's AutoGen.\n",
    "\n",
    "**Estimated Time:** 135 minutes\n",
    "\n",
    "**Introduction:**\n",
    "In the previous lab, you built agents that could use tools. Now, we will explore how to orchestrate more complex agent behaviors. First, you will build a \"plan-and-execute\" agent that first thinks about a problem and then writes the code. Second, you will use the AutoGen framework to create a team of AI agents that can collaborate on a task through conversation.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We will need to install the `pyautogen` library for the second part of this lab.\n",
    "\n",
    "**Model Selection:**\n",
    "For multi-agent systems and planning, models with strong reasoning and instruction-following are essential. `gpt-4.1` or `o3` are highly recommended for their planning capabilities.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to our individual planner/coder agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 11:38:59,626 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=gpt-4.1 latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# This helper will install packages if they are not found\n",
    "import importlib\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        importlib.import_module(package)\n",
    "    except ImportError:\n",
    "        print(f\"{package} not found, installing...\")\n",
    "        import subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "\n",
    "install_if_missing('pyautogen')\n",
    "\n",
    "from utils import setup_llm_client, get_completion\n",
    "import autogen\n",
    "\n",
    "# AutoGen is optimized for the OpenAI API format.\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): A Plan-and-Execute Agent\n",
    "\n",
    "**Task:** Create a two-step agent that first generates a detailed plan (a 'spec') for a Python function and then uses that plan to write the code.\n",
    "\n",
    "> **Hint:** The 'Plan-and-Execute' pattern separates thinking from doing. The first agent (the Planner) creates a detailed blueprint. The second agent (the Coder) is given a much simpler task: just follow the blueprint. This separation often leads to more reliable and accurate results than asking a single agent to do everything at once.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Define a high-level goal, such as: \"Create a Python function that takes a list of strings and returns a new list containing only the strings that are palindromes.\"\n",
    "2.  **Planner Agent:** Write a prompt that asks the LLM to act as a senior software architect. It should take the high-level goal and produce a detailed specification for the function, including the function signature, parameters, return value, and step-by-step logic.\n",
    "3.  **Coder Agent:** Write a second prompt. This prompt should take the detailed specification from the Planner Agent as its *only* context and instruct the LLM to write the Python code that implements the spec.\n",
    "\n",
    "**Expected Quality:** A two-stage generation process that separates the 'planning' from the 'doing', resulting in a well-defined Python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Planner Agent Generating Spec ---\n",
      "Function Signature:\n",
      "def filter_palindromes(strings: list[str]) -> list[str]\n",
      "\n",
      "Parameter Description:\n",
      "- strings: A list of strings. Each element is expected to be a string. The list may be empty.\n",
      "\n",
      "Return Value:\n",
      "- Returns a new list containing only the strings from the input list that are palindromes. The returned list preserves the original order of palindromic strings.\n",
      "\n",
      "Detailed Logic:\n",
      "1. Initialize an empty list, result, to store palindromic strings.\n",
      "2. Iterate over each string in the input list:\n",
      "    a. For each string, check if it is equal to its reverse (i.e., string == string[::-1]).\n",
      "    b. If the string is equal to its reverse, append it to the result list.\n",
      "3. After processing all strings, return the result list.\n",
      "\n",
      "Edge Cases to Consider:\n",
      "- Empty input list: Should return an empty list.\n",
      "- Strings with mixed case: By default, the function is case-sensitive ('Deed' is not a palindrome, but 'deed' is).\n",
      "- Strings containing spaces, punctuation, or other non-alphabetic characters: The check is literal, so 'nurses run' is not a palindrome unless spaces are intentionally ignored.\n",
      "- Empty strings: An empty string is generally considered a palindrome and should be included in the result.\n",
      "- Single-character strings: Any single character string is a palindrome and should be included in the result.\n",
      "- Non-string elements in the list: The function assumes all elements are strings; if not, a TypeError may occur.\n",
      "\n",
      "Example:\n",
      "Input: ['madam', 'racecar', 'apple', '', 'a', 'Deed']\n",
      "Output: ['madam', 'racecar', '', 'a']\n",
      "\n",
      "--- Coder Agent Generating Code ---\n",
      "Function Signature:\n",
      "def filter_palindromes(strings: list[str]) -> list[str]\n",
      "\n",
      "Parameter Description:\n",
      "- strings: A list of strings. Each element is expected to be a string. The list may be empty.\n",
      "\n",
      "Return Value:\n",
      "- Returns a new list containing only the strings from the input list that are palindromes. The returned list preserves the original order of palindromic strings.\n",
      "\n",
      "Detailed Logic:\n",
      "1. Initialize an empty list, result, to store palindromic strings.\n",
      "2. Iterate over each string in the input list:\n",
      "    a. For each string, check if it is equal to its reverse (i.e., string == string[::-1]).\n",
      "    b. If the string is equal to its reverse, append it to the result list.\n",
      "3. After processing all strings, return the result list.\n",
      "\n",
      "Edge Cases to Consider:\n",
      "- Empty input list: Should return an empty list.\n",
      "- Strings with mixed case: By default, the function is case-sensitive ('Deed' is not a palindrome, but 'deed' is).\n",
      "- Strings containing spaces, punctuation, or other non-alphabetic characters: The check is literal, so 'nurses run' is not a palindrome unless spaces are intentionally ignored.\n",
      "- Empty strings: An empty string is generally considered a palindrome and should be included in the result.\n",
      "- Single-character strings: Any single character string is a palindrome and should be included in the result.\n",
      "- Non-string elements in the list: The function assumes all elements are strings; if not, a TypeError may occur.\n",
      "\n",
      "Example:\n",
      "Input: ['madam', 'racecar', 'apple', '', 'a', 'Deed']\n",
      "Output: ['madam', 'racecar', '', 'a']\n",
      "\n",
      "--- Coder Agent Generating Code ---\n",
      "def filter_palindromes(strings: list[str]) -> list[str]:\n",
      "    result = []\n",
      "    for string in strings:\n",
      "        if string == string[::-1]:\n",
      "            result.append(string)\n",
      "    return result\n",
      "def filter_palindromes(strings: list[str]) -> list[str]:\n",
      "    result = []\n",
      "    for string in strings:\n",
      "        if string == string[::-1]:\n",
      "            result.append(string)\n",
      "    return result\n"
     ]
    }
   ],
   "source": [
    "high_level_goal = \"Create a Python function that takes a list of strings and returns a new list containing only the strings that are palindromes.\"\n",
    "\n",
    "## TODO: 1. Write the prompt for the Planner Agent.\n",
    "# It should take the high_level_goal and produce a detailed function specification.\n",
    "planner_prompt = f'''\n",
    "You are a senior software architect. Your task is to design a Python function based on the following high-level goal:\n",
    "\n",
    "false\n",
    "{high_level_goal}\n",
    "\n",
    "Please provide a detailed specification including:\n",
    "- The function signature\n",
    "- A description of each parameter\n",
    "- The expected return value\n",
    "- Step-by-step logic for the implementation\n",
    "- Any edge cases to consider\n",
    "(no markdown fences)\n",
    "'''\n",
    "\n",
    "print(\"--- Planner Agent Generating Spec ---\")\n",
    "function_spec = get_completion(planner_prompt, client, model_name, api_provider)\n",
    "print(function_spec)\n",
    "\n",
    "## TODO: 2. Write the prompt for the Coder Agent.\n",
    "# It should take the function_spec as context and write the final Python code.\n",
    "coder_prompt = f'''\n",
    "You are a senior Python developer. Your only context is the following specification:\n",
    "\n",
    "{function_spec}\n",
    "\n",
    "Write the complete Python function as described. Only output the code, no explanations.\n",
    "(no markdown fences)\n",
    "'''\n",
    "\n",
    "print(\"\\n--- Coder Agent Generating Code ---\")\n",
    "generated_function = get_completion(coder_prompt, client, model_name, api_provider)\n",
    "print(generated_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): A Three-Agent AutoGen Team\n",
    "\n",
    "**Task:** Use Microsoft's AutoGen framework to create a conversational team of three agents: a Product Manager, a Developer, and a User Proxy.\n",
    "\n",
    "> **Tip:** The `UserProxyAgent` is special. It acts as your representative in the chat. Setting `human_input_mode` to `TERMINATE` tells the agent that it can stop the conversation on its own once it believes the task is complete, without asking you for confirmation.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Define a `config_list` for AutoGen, which tells it which model to use.\n",
    "2.  Create a `UserProxyAgent`. This agent represents you, the human user. Set its `human_input_mode` to `TERMINATE` so the conversation stops after a solution is proposed.\n",
    "3.  Create an `AssistantAgent` named \"ProductManager\". Give it a system message defining its role (e.g., \"You are a Product Manager. Your job is to clarify requirements and create a plan.\").\n",
    "4.  Create another `AssistantAgent` named \"Developer\". Give it a system message defining its role (e.g., \"You are a senior Python developer. You write code based on the Product Manager's plan.\").\n",
    "5.  Create a `GroupChat` with all three agents and a `GroupChatManager`.\n",
    "6.  Initiate the chat with a feature request from the user proxy, like \"Add a feature to our API to calculate the complexity of a password.\"\n",
    "\n",
    "**Expected Quality:** A conversational transcript showing the Product Manager clarifying the task, the Developer writing the code, and the process terminating successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUserProxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Add a feature to our API to calculate the complexity of a password based on length, and the presence of uppercase, lowercase, numbers, and symbols.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Add a feature to our API to calculate the complexity of a password based on length, and the presence of uppercase, lowercase, numbers, and symbols.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUserProxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Add a feature to our API to calculate the complexity of a password based on length, and the presence of uppercase, lowercase, numbers, and symbols.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Add a feature to our API to calculate the complexity of a password based on length, and the presence of uppercase, lowercase, numbers, and symbols.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The group chat's internal speaker selection agent does not have an LLM configuration. Please provide a valid LLM config to the group chat's GroupChatManager or set it with the select_speaker_auto_llm_config parameter.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# TODO: 6. Initiate the chat with a feature request.\u001b[39;00m\n\u001b[32m     45\u001b[39m feature_request = \u001b[33m\"\u001b[39m\u001b[33mAdd a feature to our API to calculate the complexity of a password based on length, and the presence of uppercase, lowercase, numbers, and symbols.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[43muser_proxy\u001b[49m\u001b[43m.\u001b[49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_request\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\AG-AISOFTDEV\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1509\u001b[39m, in \u001b[36mConversableAgent.initiate_chat\u001b[39m\u001b[34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[39m\n\u001b[32m   1507\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1508\u001b[39m         msg2send = \u001b[38;5;28mself\u001b[39m.generate_init_message(message, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1509\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1510\u001b[39m summary = \u001b[38;5;28mself\u001b[39m._summarize_chat(\n\u001b[32m   1511\u001b[39m     summary_method,\n\u001b[32m   1512\u001b[39m     summary_args,\n\u001b[32m   1513\u001b[39m     recipient,\n\u001b[32m   1514\u001b[39m     cache=cache,\n\u001b[32m   1515\u001b[39m )\n\u001b[32m   1516\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\AG-AISOFTDEV\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1163\u001b[39m, in \u001b[36mConversableAgent.send\u001b[39m\u001b[34m(self, message, recipient, request_reply, silent)\u001b[39m\n\u001b[32m   1161\u001b[39m valid = \u001b[38;5;28mself\u001b[39m._append_oai_message(message, \u001b[33m\"\u001b[39m\u001b[33massistant\u001b[39m\u001b[33m\"\u001b[39m, recipient, is_sending=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1162\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[32m-> \u001b[39m\u001b[32m1163\u001b[39m     \u001b[43mrecipient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1165\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1166\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMessage can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1167\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\AG-AISOFTDEV\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1271\u001b[39m, in \u001b[36mConversableAgent.receive\u001b[39m\u001b[34m(self, message, sender, request_reply, silent)\u001b[39m\n\u001b[32m   1269\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1270\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1271\u001b[39m reply = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m=\u001b[49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1272\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1273\u001b[39m     \u001b[38;5;28mself\u001b[39m.send(reply, sender, silent=silent)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\AG-AISOFTDEV\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:2864\u001b[39m, in \u001b[36mConversableAgent.generate_reply\u001b[39m\u001b[34m(self, messages, sender, **kwargs)\u001b[39m\n\u001b[32m   2862\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   2863\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._match_trigger(reply_func_tuple[\u001b[33m\"\u001b[39m\u001b[33mtrigger\u001b[39m\u001b[33m\"\u001b[39m], sender):\n\u001b[32m-> \u001b[39m\u001b[32m2864\u001b[39m     final, reply = \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m=\u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfig\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2865\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[32m   2866\u001b[39m         log_event(\n\u001b[32m   2867\u001b[39m             \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2868\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreply_func_executed\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2872\u001b[39m             reply=reply,\n\u001b[32m   2873\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\AG-AISOFTDEV\\.venv\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:1222\u001b[39m, in \u001b[36mGroupChatManager.run_chat\u001b[39m\u001b[34m(self, messages, sender, config)\u001b[39m\n\u001b[32m   1219\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1221\u001b[39m     \u001b[38;5;66;03m# select the next speaker\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     speaker = \u001b[43mgroupchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect_speaker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1223\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silent:\n\u001b[32m   1224\u001b[39m         iostream = IOStream.get_default()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\AG-AISOFTDEV\\.venv\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:578\u001b[39m, in \u001b[36mGroupChat.select_speaker\u001b[39m\u001b[34m(self, last_speaker, selector)\u001b[39m\n\u001b[32m    575\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.next_agent(last_speaker)\n\u001b[32m    577\u001b[39m \u001b[38;5;66;03m# auto speaker selection with 2-agent chat\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auto_select_speaker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_speaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magents\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\AG-AISOFTDEV\\.venv\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:740\u001b[39m, in \u001b[36mGroupChat._auto_select_speaker\u001b[39m\u001b[34m(self, last_speaker, selector, messages, agents)\u001b[39m\n\u001b[32m    735\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._validate_speaker_name(recipient, messages, sender, config, attempts_left, attempt, agents)\n\u001b[32m    737\u001b[39m \u001b[38;5;66;03m# Two-agent chat for speaker selection\u001b[39;00m\n\u001b[32m    738\u001b[39m \n\u001b[32m    739\u001b[39m \u001b[38;5;66;03m# Agent for checking the response from the speaker_select_agent\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m checking_agent, speaker_selection_agent = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_internal_agents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    741\u001b[39m \u001b[43m    \u001b[49m\u001b[43magents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_attempts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_speaker_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselector\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    744\u001b[39m \u001b[38;5;66;03m# Create the starting message\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.select_speaker_prompt_template \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\AG-AISOFTDEV\\.venv\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:669\u001b[39m, in \u001b[36mGroupChat._create_internal_agents\u001b[39m\u001b[34m(self, agents, max_attempts, messages, validate_speaker_name, selector)\u001b[39m\n\u001b[32m    666\u001b[39m speaker_selection_llm_config = \u001b[38;5;28mself\u001b[39m.select_speaker_auto_llm_config \u001b[38;5;129;01mor\u001b[39;00m selector.llm_config\n\u001b[32m    668\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m speaker_selection_llm_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    670\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe group chat\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms internal speaker selection agent does not have an LLM configuration. Please provide a valid LLM config to the group chat\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms GroupChatManager or set it with the select_speaker_auto_llm_config parameter.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    671\u001b[39m     )\n\u001b[32m    673\u001b[39m \u001b[38;5;66;03m# Agent for selecting a single agent name from the response\u001b[39;00m\n\u001b[32m    674\u001b[39m speaker_selection_agent = ConversableAgent(\n\u001b[32m    675\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mspeaker_selection_agent\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    676\u001b[39m     system_message=\u001b[38;5;28mself\u001b[39m.select_speaker_msg(agents),\n\u001b[32m   (...)\u001b[39m\u001b[32m    680\u001b[39m     \u001b[38;5;66;03m# Suppresses some extra terminal outputs, outputs will be handled by select_speaker_auto_verbose\u001b[39;00m\n\u001b[32m    681\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: The group chat's internal speaker selection agent does not have an LLM configuration. Please provide a valid LLM config to the group chat's GroupChatManager or set it with the select_speaker_auto_llm_config parameter."
     ]
    }
   ],
   "source": [
    "# TODO: 1. Define the config_list for the LLM.\n",
    "# Tip: This should be a list containing a dictionary with 'model' and 'api_key'.\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": model_name,\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "    }\n",
    " ]\n",
    "\n",
    "# TODO: 2. Create the UserProxyAgent.\n",
    "# Tip: Use autogen.UserProxyAgent and set the human_input_mode.\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"UserProxy\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    max_consecutive_auto_reply=3,\n",
    "    llm_config={\"config_list\": config_list}\n",
    " )\n",
    "\n",
    "# TODO: 3. Create the ProductManager agent.\n",
    "# Tip: Use autogen.AssistantAgent and provide a system_message.\n",
    "product_manager = autogen.AssistantAgent(\n",
    "    name=\"ProductManager\",\n",
    "    system_message=\"You are a Product Manager. Your job is to clarify requirements and create a plan.\",\n",
    "    llm_config={\"config_list\": config_list}\n",
    " )\n",
    "\n",
    "# TODO: 4. Create the Developer agent.\n",
    "developer = autogen.AssistantAgent(\n",
    "    name=\"Developer\",\n",
    "    system_message=\"You are a senior Python developer. You write code based on the Product Manager's plan.\",\n",
    "    llm_config={\"config_list\": config_list}\n",
    " )\n",
    "\n",
    "# TODO: 5. Create the GroupChat and GroupChatManager.\n",
    "groupchat = autogen.GroupChat(\n",
    "    agents=[user_proxy, product_manager, developer],\n",
    "    messages=[],\n",
    "    max_round=10\n",
    " )\n",
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=groupchat\n",
    " )\n",
    "\n",
    "# TODO: 6. Initiate the chat with a feature request.\n",
    "feature_request = \"Add a feature to our API to calculate the complexity of a password based on length, and the presence of uppercase, lowercase, numbers, and symbols.\"\n",
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=feature_request\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Multi-Agent System with a Code Reviewer\n",
    "\n",
    "**Task:** Add a fourth agent, the `CodeReviewer`, to your AutoGen team. The conversation must now continue until the reviewer formally approves the developer's code.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Keep the three agents from the previous challenge.\n",
    "2.  Create a new `AssistantAgent` named \"CodeReviewer\". Its system message should instruct it to review Python code for quality, correctness, and adherence to best practices. It must end its review with the word \"APPROVED\" if the code is satisfactory.\n",
    "3.  Modify the `UserProxyAgent`'s `is_termination_msg` property. This function should now check if the reviewer's last message contains the word \"APPROVED\".\n",
    "4.  Create a new `GroupChat` with all four agents.\n",
    "5.  Initiate the chat with the same feature request. Observe the conversation loop: the developer writes code, the reviewer critiques it, the developer revises the code, and the process repeats until the reviewer approves.\n",
    "\n",
    "**Expected Quality:** A longer, more complex conversational transcript showing a collaborative loop of coding and reviewing, demonstrating a more realistic and robust development workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 1. Create the CodeReviewer agent.\n",
    "code_reviewer = None # Your agent here\n",
    "\n",
    "# TODO: 2. Create a new UserProxyAgent with a custom termination message check.\n",
    "# Tip: The `is_termination_msg` property accepts a lambda function.\n",
    "user_proxy_with_review = autogen.UserProxyAgent(\n",
    "    name=\"UserProxyWithReview\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    is_termination_msg=None # Your lambda function here\n",
    ")\n",
    "\n",
    "# TODO: 3. Create the new 4-agent GroupChat and Manager.\n",
    "four_agent_groupchat = None # Your group chat here\n",
    "four_agent_manager = None # Your manager here\n",
    "\n",
    "# TODO: 4. Initiate the chat.\n",
    "# user_proxy_with_review.initiate_chat(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Excellent work! You have now explored two powerful advanced agentic architectures. You learned how the plan-and-execute model can lead to more structured and reliable code generation, and you used AutoGen to simulate a collaborative team of AI agents that can plan, code, and review work. These foundational patterns are the building blocks for creating highly sophisticated and autonomous AI systems.\n",
    "\n",
    "> **Key Takeaway:** Multi-agent systems allow you to break down a complex problem into smaller, more manageable tasks, each handled by a specialized AI agent. This division of labor, whether in a sequential 'plan-and-execute' pattern or a collaborative conversation, often leads to higher quality and more reliable results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
